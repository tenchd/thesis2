\unnumberedchapter{Introduction}
\label{chap:intro}

%\addcontentsline{toc}{chapter}{\nameref{chap0}}

When designing and analyzing algorithms it is typically assumed that the input is easily and conveniently accessible.  For example, when designing an algorithm to sort an array of integers we assume that we can write to or read from any position in the array at any moment, and each such operation can be performed very quickly.  In such a case we say that we have \emph{random access} to the input, meaning that any part of the input may be accessed at any time for unit cost.

The vast growth in recent years of the scope of computing and data science challenges often leads to circumstances which complicate this standard model of computation.  For instance, the input we wish to run an algorithm on may be massive -- larger than can fit in the RAM of available computers.  An input may be distributed across many different storage devices, or accessible only via noisy or expensive sensors.  Such conditions have the potential to violate the random access assumption:  perhaps we are only able to access some subset of the input at any time, or maybe we pay a significant cost for any access operation.

In this proposal we investigate algorithmic challenges in two broad settings where aspects of the random access assumption fail: the \emph{streaming} domain, where a massive input is only accessible as an arbitrarily-ordered sequence of elements and working memory is sharply limited; and \emph{query-accessible} inputs, for which accessing a piece of the input requires the algorithm to pay a high price in computation time, energy, money, durability, or some other scarce resource.

\section{Overview}

In Chapter~\ref{chap:vertex}, we describe the dynamic graph streaming model, where a graph is defined by a sequence of edge insertions and deletions and we must compute some property of this graph given only one-way access to the input sequence and limited working memory.  We then present algorithms and lower bounds for vertex connectivity, graph reconstruction, and hypergraph sparsification in this model.  In Chapter~\ref{chap:mesh}, we present \Mesh, a memory manager for C and C++ that performs memory compaction despite the fact that this has long been thought to be impossible in these languages. We demonstrate that the problem of efficiently compacting memory in these languages can be reduced to an algorithmic graph problem, analytically prove that \Mesh's core query-based meshing algorithm performs significant memory compaction with high probability, and empirically verify its performance.  In Chapter~\ref{chap:futurework} we describe current and future research projects, including computing maximum unique cover and capacitated maximum cut in graph streams, extensions to the graph streaming model where edges exist at some times and not others, a network measurement system that makes efficient use of limited measurement resources, and query-based graph reconstruction problems.

Finally, in Chapter~\ref{chap:roadmap}, we propose a timeline for progress on these current and new projects, culminating in the thesis defense.